{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import csv\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Scipy\n",
    "import numpy as np\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.utils\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter\n",
    "import IPython.display\n",
    "\n",
    "# Program-specific\n",
    "sys.path.append('../modules')\n",
    "import constants\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prestonh/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "df_train = functions.LoadTrainData(aug = True, mix = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NA values w/ file values\n",
    "fill_file_path = '../data/train/missing_inc_angles.csv'\n",
    "functions.FillMissing(df_train, fill_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds cross-validation for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogLoss(predicted_probas, labels):\n",
    "    return -(np.dot(labels, np.log(predicted_probas)) + np.dot((1-labels), np.log(1-predicted_probas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 1.5000000000000002e-05, 2.25e-05, 3.375e-05, 5.0625000000000004e-05, 7.593750000000001e-05, 0.00011390625000000001]\n"
     ]
    }
   ],
   "source": [
    "Cs = [1e-5*(1.5**i) for i in range(7)]\n",
    "print(Cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfolds = sklearn.model_selection.KFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0 / 7 \t\tC =  1e-05\n",
      "0.558663622868\n"
     ]
    }
   ],
   "source": [
    "errors = [0 for i in range(len(Cs))]\n",
    "for i, C in enumerate(Cs):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Benchmarking\n",
    "    '''\n",
    "    IPython.display.clear_output()\n",
    "    print('i = ', str(i), '/', str(len(Cs)), '\\t\\tC = ', C)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for train_indices, valid_indices in kfolds.split(df_train):\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "        # Create model\n",
    "        model = sklearn.linear_model.LogisticRegression(C = C)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(df_train[constants.inputs].iloc[train_indices], df_train[constants.output].iloc[train_indices])\n",
    "\n",
    "        # Test model\n",
    "        predictions = model.predict_proba(df_train[constants.inputs].iloc[valid_indices])[:,1]\n",
    "\n",
    "        # Get errors\n",
    "        errors[i] += functions.LogLoss(predictions, df_train[constants.output].iloc[valid_indices])\n",
    "        \n",
    "        print(errors[i])\n",
    "        \n",
    "        break\n",
    "        \n",
    "        \n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogx(Cs, errors, marker = 'o')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Log loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Cs)):\n",
    "    print(Cs[i], '\\t\\t', errors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = functions.LoadTrainData(aug = False, mix = True)\n",
    "df_test = functions.LoadTestData(mix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = constants.inputs\n",
    "output = constants.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NA values w/ file values\n",
    "fill_file_path = '../data/missing_inc_angles.csv'\n",
    "functions.FillMissing(df_train, fill_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create\n",
    "model = sklearn.linear_model.LogisticRegression(C = 5e-5)\n",
    "\n",
    "# Fit\n",
    "model.fit(df_train[inputs], df_train[output])\n",
    "\n",
    "# Test\n",
    "predictions = model.predict_proba(df_test[inputs])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file_path = '../data/submissions/submission_' + str(datetime.datetime.now().date()) + '_' + str(datetime.datetime.now().time()).replace(':', '-').split('.')[0]\n",
    "\n",
    "with open(output_file_path, 'w') as output_file_handle:\n",
    "    file_writer = csv.writer(output_file_handle, delimiter = ',')\n",
    "    \n",
    "    file_writer.writerow(['id', 'is_iceberg'])\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        file_writer.writerow([df_test.index.values[i], predictions[i]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
